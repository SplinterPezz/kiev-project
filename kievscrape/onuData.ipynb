{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from pymongo import MongoClient\n",
    "import calendar\n",
    "import urllib.request\n",
    "import PyPDF2\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "data_onu_url = \"https://ukraine.un.org/en/search?key=Ukraine%20civilian%20casualties&page=\"\n",
    "main_domain = \"https://ukraine.un.org\"\n",
    "article_valid = \"civilian casualties\"\n",
    "\n",
    "mongo_url = \"mongodb://\"\n",
    "mongo_db = \"kiev\"\n",
    "mongo_collection_article = \"onuData\"\n",
    "list_of_values_txt = [\"killed\",\" men\",\"women\",\"girls\",\"boys\",\"children\",\"adults\",\"injured\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_onu_url(page):\n",
    "    return data_onu_url + str(page)\n",
    "\n",
    "def find_last_page(onu_text):\n",
    "    find_number = [m.start() for m in re.finditer('Showing 1 to', onu_text)]\n",
    "    if len(find_number) == 1:\n",
    "        position = find_number[0]\n",
    "        text_found = onu_text[position:position+100]\n",
    "        \n",
    "        if len(text_found) > 0:\n",
    "            text_found_splitted = text_found.split('<')\n",
    "\n",
    "            if len(text_found_splitted) > 0:\n",
    "                text_found_cleaned = text_found_splitted[0].strip()\n",
    "                \n",
    "                search_last_two_number = text_found_cleaned.split(' ')\n",
    "\n",
    "                number_list = []\n",
    "                for any in search_last_two_number:\n",
    "                    try:\n",
    "                        converted = int(any)\n",
    "                        number_list.append(converted)\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                if len(number_list) == 3:\n",
    "                    pages_number = int(number_list[2] / number_list[1])\n",
    "                    return pages_number\n",
    "    return None\n",
    "\n",
    "def create_articles(title, url):\n",
    "    article = {\n",
    "        \"title\": title,\n",
    "        \"url\": url\n",
    "    }\n",
    "    return article\n",
    "\n",
    "def get_articles(soup):\n",
    "    article_list_from_soup = []\n",
    "    article_test = soup.find_all('a', {\"class\": \"text-3xl\"})\n",
    "    for any in article_test:\n",
    "        this_title = any.text\n",
    "        if article_valid in this_title.lower():\n",
    "            for month in my_calendar_list:\n",
    "                if month in this_title.lower():\n",
    "                    this_url = any.get(\"href\")\n",
    "                    this_article = create_articles(this_title, main_domain + this_url)\n",
    "                    article_list_from_soup.append(this_article)\n",
    "                    break\n",
    "    return article_list_from_soup\n",
    "\n",
    "def append_article_to_list(article_list, articles):\n",
    "    for any in articles:\n",
    "        article_list.append(any)\n",
    "    return article_list\n",
    "\n",
    "def get_all_articles():\n",
    "    start_page = 0\n",
    "    onu_response = requests.get(get_onu_url(start_page))\n",
    "    onu_text = onu_response.text\n",
    "    soup_first_page = BeautifulSoup(onu_text, 'html5lib')\n",
    "    last_page = find_last_page(onu_text)\n",
    "    \n",
    "    article_list = []\n",
    "    if last_page is not None:\n",
    "        for page in range(last_page + 1):\n",
    "            articles = []\n",
    "            \n",
    "            if page == 0:\n",
    "                articles = get_articles(soup_first_page)\n",
    "            else:\n",
    "                page_url = get_onu_url(page)\n",
    "                print(page_url)\n",
    "                page_response = requests.get(page_url)\n",
    "                onu_text = page_response.text\n",
    "                soup_page = BeautifulSoup(onu_text, 'html5lib')\n",
    "                articles = get_articles(soup_page)\n",
    "\n",
    "            if len(articles) > 0:\n",
    "                article_list = append_article_to_list(article_list, articles)\n",
    "            \n",
    "            time.sleep(5)\n",
    "            \n",
    "    return article_list\n",
    "\n",
    "def clean_article_list(article_list):\n",
    "    new_article_list = []\n",
    "    for art in article_list:\n",
    "        found = False\n",
    "        \n",
    "        for new_art in new_article_list:\n",
    "            if art['url'] == new_art['url']:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            new_article_list.append(art)\n",
    "    \n",
    "    return new_article_list\n",
    "\n",
    "def connect_mongo(mongo_url, mongo_db):\n",
    "    client = MongoClient(mongo_url)\n",
    "    mongo_db_instance = client[mongo_db]\n",
    "    return mongo_db_instance\n",
    "\n",
    "def get_collection(mongo_db_instance, collection_to_get):\n",
    "    collection = mongo_db_instance[collection_to_get]\n",
    "    return collection\n",
    "\n",
    "def insert_in_collection(list_to_add, collection):\n",
    "    collection.insert_many(list_to_add)\n",
    "\n",
    "def get_calendar_list():\n",
    "    list_calendar = list(calendar.month_name)\n",
    "    my_calendar_list = []\n",
    "    for any in list_calendar:\n",
    "        if len(any) > 0:\n",
    "            my_calendar_list.append(any.lower())\n",
    "    return my_calendar_list\n",
    "\n",
    "def get_download_link_from_url(url):\n",
    "    onu_response_test = requests.get(url)\n",
    "    onu_text_test = onu_response_test.text\n",
    "    soup_page_test = BeautifulSoup(onu_text_test, 'html5lib')\n",
    "\n",
    "    downloads = soup_page_test.find_all('i', {\"class\": \"fa fa-download\"})\n",
    "    download_list = []\n",
    "    for any in downloads:\n",
    "        parent = any.find_parent().find_parent().find_parent()\n",
    "        if 'English' in parent.text:\n",
    "            parent_a = parent.find('a')\n",
    "            if parent_a is not None:\n",
    "                parent_a_href = parent_a.get('href')\n",
    "\n",
    "                if parent_a_href is not None:\n",
    "                    download_list.append(main_domain + parent_a_href)\n",
    "\n",
    "    if len(download_list) == 1:\n",
    "        return download_list[0]\n",
    "    return None\n",
    "\n",
    "def add_download_to_articles(all_articles):\n",
    "    new_article_list = []\n",
    "    for any in all_articles:\n",
    "        new_article = any.copy()\n",
    "        article_url = any['url']\n",
    "        download = get_download_link_from_url(article_url)\n",
    "\n",
    "        if download is not None:\n",
    "            new_article['download'] = download\n",
    "            new_article_list.append(new_article)\n",
    "        else:\n",
    "            print(\"Cannot download this article \" + article_url)\n",
    "        time.sleep(5)\n",
    "    return new_article_list\n",
    "\n",
    "def remove_all_article_present(article_list):\n",
    "    new_article_list = []\n",
    "    print(\"searching for duplicates : \" + str(len(article_list)))\n",
    "    for art in article_list:\n",
    "        print(\"searching for : \" + art['title'])\n",
    "        articles_db = collection_article.find({'title': art['title']})\n",
    "\n",
    "        articles_found = False\n",
    "        for any in articles_db:\n",
    "            articles_found = True\n",
    "            break\n",
    "\n",
    "        if articles_found:\n",
    "            continue\n",
    "        new_article_list.append(art)\n",
    "    return new_article_list\n",
    "\n",
    "def download_file(download_url, filename):\n",
    "    response = urllib.request.urlopen(download_url)\n",
    "    file = open(filename + \".pdf\", 'wb')\n",
    "    file.write(response.read())\n",
    "    file.close()\n",
    "    i = response.info()\n",
    "    i.keys()\n",
    "    article_date = None\n",
    "    try:\n",
    "        date_time_str = i.get('Last-Modified')\n",
    "        date_time_obj = datetime.strptime(date_time_str, '%a, %d %b %Y %H:%M:%S GMT')\n",
    "        article_date = date_time_obj\n",
    "    except:\n",
    "        article_date = None\n",
    "    return article_date\n",
    "\n",
    "def search_death_regex(synonym, text):\n",
    "    expression = r\"(?i)(?:\\b\" + synonym + \"\\D{0,20})([0-9][0-9,]*)[^.,]|([0-9][0-9,]*)[^.,](?:\\D{0,20}\" + synonym + \")\"\n",
    "    values = re.findall(expression, text)\n",
    "    return values\n",
    "\n",
    "def search_death(article_body, to_find):\n",
    "    matches = search_death_regex(to_find, article_body)\n",
    "    if not matches:\n",
    "        return []\n",
    "    return [item for sublist in matches if sublist for item in sublist if item]\n",
    "\n",
    "def extract_text_from_last_file(filename):\n",
    "    pdf_file_obj = open(filename + '.pdf', 'rb')     #'rb' for read binary mode\n",
    "    pdf_reader = PyPDF2.PdfFileReader(pdf_file_obj)\n",
    "    page_obj = pdf_reader.getPage(0) \n",
    "    pdf_extracted = page_obj.extractText()\n",
    "    pdf_file_obj.close()\n",
    "    pdf_extracted = pdf_extracted.replace('\\n','')\n",
    "    list_of_dot = pdf_extracted.split('-')\n",
    "    new_list_of_dot = []\n",
    "    for list in list_of_dot:\n",
    "        if 'total' in list:\n",
    "            list = list.split(')')\n",
    "            new_list_of_dot.append(list[0])\n",
    "    return new_list_of_dot, pdf_extracted\n",
    "\n",
    "def get_dot_values(new_list_of_dot):\n",
    "    dot_lists = []\n",
    "    for row in new_list_of_dot:\n",
    "        object_value = {}\n",
    "        for to_search in list_of_values_txt:\n",
    "            values = search_death(row, to_search)\n",
    "            list_of_int = []\n",
    "            if values is not None:\n",
    "                for integer in values:\n",
    "                    integer = integer.replace(',', '')\n",
    "                    list_of_int.append(int(integer))\n",
    "\n",
    "                object_value[to_search.strip()] = list_of_int\n",
    "        if len(object_value) > 0:\n",
    "            dot_lists.append(object_value)\n",
    "    return dot_lists\n",
    "\n",
    "def extract_from_object(my_object):\n",
    "    keys = [\n",
    "        'killed', 'men', 'women', 'girls',\n",
    "        'boys', 'children', 'adults', 'injured'\n",
    "    ]\n",
    "\n",
    "    def extract_value(key):\n",
    "        try:\n",
    "            value = my_object.get(key)\n",
    "            if isinstance(value, list):\n",
    "                return value[0] if len(value) == 1 else value\n",
    "        except Exception:\n",
    "            pass\n",
    "        return None\n",
    "\n",
    "    return tuple(extract_value(key) for key in keys)\n",
    "\n",
    "def get_article_downloaded_value(new_article_list):\n",
    "    article_list_updated = []\n",
    "    for article in new_article_list:\n",
    "        file_name = \"last\"\n",
    "        article_create_date = download_file(article['download'], file_name)\n",
    "        new_list_of_dot, full_text = extract_text_from_last_file(file_name)\n",
    "        delete_file(file_name)\n",
    "        dot_lists = get_dot_values(new_list_of_dot)\n",
    "        \n",
    "        if len(dot_lists) == 2:\n",
    "            death_values, injuried_values = extract_values_from_dot_lists(dot_lists)\n",
    "            article['death'] = death_values\n",
    "            article['injuried'] = injuried_values\n",
    "        else:\n",
    "            if len(dot_lists) == 0:\n",
    "                dot_lists = extract_dots_v2(full_text)\n",
    "                dot_lists = get_dot_values(dot_lists)\n",
    "                \n",
    "                if len(dot_lists) == 2:\n",
    "                    death_values, injuried_values = extract_values_from_dot_lists(dot_lists)\n",
    "                    article['death'] = death_values\n",
    "                    article['injuried'] = injuried_values\n",
    "                else:\n",
    "                    article['deathValues'] = dot_lists\n",
    "            else:\n",
    "                article['deathValues'] = dot_lists\n",
    "        \n",
    "        article['createDate'] = article_create_date\n",
    "        article['fullDocument'] = full_text\n",
    "        article_list_updated.append(article)\n",
    "        \n",
    "        time.sleep(5)\n",
    "    return article_list_updated\n",
    "\n",
    "\n",
    "def extract_values_from_dot_lists(dot_lists):\n",
    "    death = dot_lists[0]\n",
    "    injuried = dot_lists[1]\n",
    "    death_total, death_men, death_women, death_girls, death_boys, death_children, death_adults, injured_total_useless = extract_from_object(death)\n",
    "    death_total_useless, injuried_men, injuried_women, injuried_girls, injuried_boys, injuried_children, injuried_adults, injured_total = extract_from_object(injuried)\n",
    "    \n",
    "    if (death_total is None and death_men is None and death_women is None and death_girls is None and death_boys is None and death_children is None and death_adults is None):\n",
    "        death_values = None\n",
    "    else:\n",
    "        death_values = {\n",
    "            'total': death_total,\n",
    "            'men': death_men,\n",
    "            'women': death_women,\n",
    "            'girls': death_girls,\n",
    "            'boys': death_boys,\n",
    "            'children': death_children,\n",
    "            'adults': death_adults\n",
    "        }\n",
    "    \n",
    "    if (injuried_men is None and injuried_women is None and injuried_girls is None and injuried_boys is None and injuried_children is None and injuried_adults is None and injured_total is None):\n",
    "        injuried_values = None\n",
    "    else:\n",
    "        injuried_values = {\n",
    "            'total': injured_total,\n",
    "            'men': injuried_men,\n",
    "            'women': injuried_women,\n",
    "            'girls': injuried_girls,\n",
    "            'boys': injuried_boys,\n",
    "            'children': injuried_children,\n",
    "            'adults': injuried_adults\n",
    "        }\n",
    "\n",
    "    return death_values, injuried_values\n",
    "def extract_dots_v2(text):\n",
    "    text_splitted = text.split('.')\n",
    "    dots = [segment for segment in text_splitted if 'killed' in segment and ' men' in segment]\n",
    "\n",
    "    if len(dots) == 1:\n",
    "        value = dots[0]\n",
    "        value_splitted = value.split(')')\n",
    "        new_dots = [seg for seg in value_splitted if 'killed' in seg or 'injured' in seg]\n",
    "        return new_dots\n",
    "\n",
    "    return dots\n",
    "\n",
    "\n",
    "def delete_file(filename):\n",
    "    os.remove(filename + \".pdf\")\n",
    "\n",
    "\n",
    "def update_date(updated_article_list):\n",
    "    new_article_list = []\n",
    "    for article in updated_article_list:\n",
    "        new_article = article.copy()\n",
    "        title = article['title']\n",
    "        article_date = None\n",
    "        title_splitted = title.split(' ')\n",
    "        int_values = []\n",
    "\n",
    "        for val in title_splitted:\n",
    "            try:\n",
    "                int_values.append(int(val))\n",
    "            except ValueError:\n",
    "                for month in my_calendar_list:\n",
    "                    if month in val.lower():\n",
    "                        try:\n",
    "                            int_values.append(datetime.strptime(val, \"%B\").month)\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "\n",
    "        if len(int_values) == 3:\n",
    "            try:\n",
    "                article_date = datetime(int_values[2], int_values[1], int_values[0])\n",
    "            except:\n",
    "                article_date = None\n",
    "\n",
    "        new_article['date'] = article_date\n",
    "        new_article_list.append(new_article)\n",
    "\n",
    "    if new_article_list:\n",
    "        return new_article_list\n",
    "\n",
    "    print(\"CANNOT UPDATE DATE OR TITLE\")\n",
    "    return updated_article_list\n",
    "\n",
    "\n",
    "def update_title(article_list):\n",
    "    updated_list = []\n",
    "    for article in article_list:\n",
    "        new_article = article.copy()\n",
    "        new_article['title'] = article['title'].replace('\\xa0', ' ')\n",
    "        updated_list.append(new_article)\n",
    "    return updated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ukraine.un.org/en/search?key=Ukraine%20civilian%20casualties&page=1\n",
      "https://ukraine.un.org/en/search?key=Ukraine%20civilian%20casualties&page=2\n",
      "https://ukraine.un.org/en/search?key=Ukraine%20civilian%20casualties&page=3\n",
      "https://ukraine.un.org/en/search?key=Ukraine%20civilian%20casualties&page=4\n",
      "https://ukraine.un.org/en/search?key=Ukraine%20civilian%20casualties&page=5\n",
      "https://ukraine.un.org/en/search?key=Ukraine%20civilian%20casualties&page=6\n",
      "https://ukraine.un.org/en/search?key=Ukraine%20civilian%20casualties&page=7\n",
      "https://ukraine.un.org/en/search?key=Ukraine%20civilian%20casualties&page=8\n",
      "searching for duplicates : 31\n",
      "searching for : Ukraine: Civilian casualties as of 18 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 15 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 16 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 21 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 23 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 26 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 29 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 25 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 28 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 1 April 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24.00 27 February 2022\n",
      "searching for : Ukraine: Civilian casualties as of 19 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 27 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 31 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 4 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 6 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 9 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 2 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 14 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 3 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 13 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 28 February 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 5 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 7 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 10 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 11 March 2022\n",
      "searching for : Ukraine: Civilian casualties as of 24:00 12 March 2022\n",
      "searching for : Conflict-related civilian casualties in Ukraine as of 31 March 2021\n",
      "searching for : Conflict-related civilian casualties in Ukraine as of 8 October 2021\n",
      "searching for : Conflict-related civilian casualties in Ukraine as of 6 May 2021\n",
      "articles to add : 3\n",
      "Cannot download this articlehttps://ukraine.un.org/en/175776-ukraine-civilian-casualties-23-march-2022\n"
     ]
    }
   ],
   "source": [
    "mongo_db = connect_mongo(mongo_url, mongo_db_name)\n",
    "collection_article = get_collection(mongo_db, mongo_collection_article)\n",
    "my_calendar_list = get_calendar_list()\n",
    "\n",
    "all_articles = get_all_articles()\n",
    "all_articles = clean_article_list(all_articles)\n",
    "new_article_list = update_title(all_articles)\n",
    "new_article_list = remove_all_article_present(new_article_list)\n",
    "print(\"articles to add : \" + str(len(new_article_list)))\n",
    "new_article_list = add_download_to_articles(new_article_list)\n",
    "updated_article_list = get_article_downloaded_value(new_article_list)\n",
    "updated_article_list_v2 = update_date(updated_article_list)\n",
    "insert_in_collection(updated_article_list_v2, collection_article)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92b7e0ce4c1cde783add4255e100d44ea3902933f047c43a85c7947d54610b37"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
